{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants\n",
    "m_p=938.27231 #MeV\n",
    "m_n=939.56563 #MeV\n",
    "t_lab=rxn_observable['energy'] #Mev\n",
    "k_p=np.sqrt(((m_p**2)*(t_lab)*(t_lab+2*m_n))/(((m_p+m_n)**2)+(2*t_lab*m_p))) #fm^-1\n",
    "k_n=np.sqrt((1/2)*m_p*t_lab) #fm^-1\n",
    "hbar_c=197.327053 #MeVfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_total=pd.read_csv('CSV_files/np.dat.csv')\n",
    "pp_total=pd.read_csv('CSV_files/pp.dat.csv')\n",
    "pp_total.rename(columns={' scattering_angle': 'scattering_angle', ' experimental_value': 'experimental_value', ' statistical_error': 'statistical_error', ' reaction_type': 'reaction_type', ' observable': 'observable', ' systematic_error': 'systematic_error', ' normalization': 'normalization'}, inplace=True)\n",
    "np_total.rename(columns={' scattering_angle': 'scattering_angle', ' experimental_value': 'experimental_value', ' statistical_error': 'statistical_error', ' reaction_type': 'reaction_type', ' observable': 'observable', ' systematic_error': 'systematic_error', ' normalization': 'normalization'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read separated files\n",
    "#np files\n",
    "np_sgt=pd.read_csv('CSV_files/np.sgt.csv')\n",
    "np_sgtl=pd.read_csv('CSV_files/np.sgtl.csv')\n",
    "np_sgtr=pd.read_csv('CSV_files/np.sgtr.csv')\n",
    "np_sgtt=pd.read_csv('CSV_files/np.sgtt.csv')\n",
    "\n",
    "#pp files\n",
    "pp_sgt=pd.read_csv('CSV_files/pp.sgt.csv')\n",
    "pp_sgte=pd.read_csv('CSV_files/pp.sgte.csv')\n",
    "pp_sgtl=pd.read_csv('CSV_files/pp.sgtl.csv')\n",
    "pp_sgtr=pd.read_csv('CSV_files/pp.sgtr.csv')\n",
    "pp_sgtt=pd.read_csv('CSV_files/pp.sgtt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove uneccesary columns\n",
    "#total files\n",
    "pp_total = pp_total.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "np_total = np_total.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "#np files\n",
    "np_sgt = np_sgt.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "np_sgtl = np_sgtl.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "np_sgtr = np_sgtr.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "np_sgtt = np_sgtt.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "#pp files\n",
    "pp_sgt = pp_sgt.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "pp_sgte = pp_sgte.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "pp_sgtl = pp_sgtl.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "pp_sgtr = pp_sgtr.drop(columns=['statistical_error', 'systematic_error', 'normalization'])\n",
    "pp_sgtt = pp_sgtt.drop(columns=['statistical_error', 'systematic_error', 'normalization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "def generate_plot(rxn_observable, reac_observ):\n",
    "    #define values to be plotted\n",
    "    energy=rxn_observable['energy']\n",
    "    value=rxn_observable['experimental_value']\n",
    "    angle=rxn_observable['scattering_angle']\n",
    "    #figure specifications\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (15,10))\n",
    "    fig.autofmt_xdate(rotation = 45)\n",
    "    fig.suptitle('Reaction_Observable: {}'.format(reac_observ), fontsize=24)\n",
    "    #plot 1\n",
    "    ax1.plot(energy, value, 'ro', alpha=0.5)\n",
    "    ax1.set_xlabel('Energy'); ax1.set_ylabel('Experimental Value'); ax1.set_title('Experimental Value vs. Energy')\n",
    "    #plot 2\n",
    "    ax2.plot(angle, value, 'bo', alpha=0.5)\n",
    "    ax2.set_xlabel('Scattering Angle'); ax2.set_ylabel('Experimental Value'); ax2.set_title('Experimental Value vs. Scattering Angle')\n",
    "    #plot 3\n",
    "    ax3.plot(angle, energy, 'go', alpha=0.5)\n",
    "    ax3.set_xlabel('Scattering Angle'); ax3.set_ylabel('Energy'); ax3.set_title('Scattering Angle vs. Energy')\n",
    "    #plot 4\n",
    "    ax4.plot(energy, angle, 'mo', alpha=0.5)\n",
    "    ax4.set_xlabel('Energy'); ax4.set_ylabel('Scattering Angle'); ax4.set_title('Energy vs. Scattering Angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EVERYTHING THAT NEEDS CHANGED SHOULD BE IN HERE\n",
    "\n",
    "#define rxn and observable for this round of calculations\n",
    "rxn_observable=np_sgt\n",
    "reac_observ='NP_SGT'\n",
    "\n",
    "#define number of random states\n",
    "number_of_random_states=10\n",
    "\n",
    "#define intervals of test size\n",
    "intervals=19 # 1:50%, 3:25%, 4:20%, 9:10%, 19:5%, 24:4%, 49:2%, 99:1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "rxn_observable = pd.get_dummies(rxn_observable)\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(rxn_observable['experimental_value'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features = rxn_observable.drop('experimental_value', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "def split_and_score(size, number_of_random_states):\n",
    "    test=np.zeros(number_of_random_states)\n",
    "    train=np.zeros(number_of_random_states)\n",
    "    for j in range(number_of_random_states):\n",
    "        #split\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=size)\n",
    "        #replace any test_labels=0 with small number to prevent dividing by 0\n",
    "        #for index, value in enumerate(test_labels):\n",
    "         #   if (value == 0):\n",
    "          #      value=1e-3\n",
    "           #     test_labels=np.where(test_labels==0, value, test_labels)\n",
    "        #rf.train\n",
    "        rf = RandomForestRegressor(n_estimators=1000)\n",
    "        rf.fit(train_features, train_labels);\n",
    "        predictions = rf.predict(test_features)\n",
    "        rf_new = RandomForestRegressor(n_estimators = 100, criterion = 'mse', max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "        importances = list(rf.feature_importances_)\n",
    "        feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "        feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "        #score\n",
    "        test[j]=rf.score(test_features,test_labels)\n",
    "        train[j]=rf.score(train_features,train_labels)\n",
    "    test_ave=np.mean(test)\n",
    "    train_ave=np.mean(train)\n",
    "    test_var=np.sqrt(np.var(test))\n",
    "    train_var=np.sqrt(np.var(train))\n",
    "    return test_ave, test_var, train_ave, train_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "test_mean=np.zeros(intervals) \n",
    "train_mean=np.zeros(intervals) \n",
    "test_variance=np.zeros(intervals) \n",
    "train_variance=np.zeros(intervals) \n",
    "for i in range(intervals): \n",
    "    #define size\n",
    "    size=(i+1)/(intervals+1)\n",
    "    #call split function\n",
    "    test, test_v, train, train_v = split_and_score(size, number_of_random_states)\n",
    "    #add to arrays\n",
    "    test_mean[i]=test\n",
    "    train_mean[i]=train\n",
    "    test_variance[i]=test_v\n",
    "    train_variance[i]=train_v\n",
    "print(\"Average Testing Score:\", test_mean)\n",
    "print('Testing Variance', test_variance)\n",
    "print('')\n",
    "print('Average Training Score', train_mean)\n",
    "print('Training Variance', train_variance)\n",
    "print('')\n",
    "\n",
    "#plot \n",
    "\n",
    "#x-axis\n",
    "if intervals==1:\n",
    "    sample_size=[50] #50% intervals\n",
    "elif intervals==3:\n",
    "    sample_size=list(range(25,76,25)) #25% intervals\n",
    "elif intervals==4:\n",
    "    sample_size=list(range(20,81,20)) #20% intervals \n",
    "elif intervals==9:\n",
    "    sample_size=list(range(10,91,10)) #10% intervals\n",
    "elif intervals==19:\n",
    "    sample_size=list(range(5,96,5)) #5% intervals\n",
    "elif intervals==24:\n",
    "    sample_size=list(range(4,97,4)) #4% intervals\n",
    "elif intervals==49:\n",
    "    sample_size=list(range(2,99,2)) #2% intervals\n",
    "elif intervals==99:\n",
    "    sample_size=list(range(1,100,1)) #1% intervals\n",
    "\n",
    "#figure\n",
    "figure(figsize=(15, 5))\n",
    "ax=plt.subplot(111)\n",
    "plt.xlabel('Test Size (%)')\n",
    "plt.ylabel('Score')\n",
    "plt.title(\"Reaction_Observable: {}\".format(reac_observ))\n",
    "plt.xlim(left=0, right=100)\n",
    "ax.scatter(sample_size, test_mean, s=100, label='Average Testing Score')\n",
    "ax.scatter(sample_size, train_mean, s=100, label='Average Training Score')\n",
    "ax.errorbar(sample_size, test_mean, yerr=test_variance, linestyle='none', capsize=10, elinewidth=2)\n",
    "ax.errorbar(sample_size, train_mean, yerr=train_variance, linestyle='none', capsize=10, elinewidth=2)\n",
    "ax.legend(loc='best')\n",
    "plt.show\n",
    "\n",
    "generate_plot(rxn_observable, reac_observ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
